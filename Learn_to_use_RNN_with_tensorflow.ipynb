{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### A simple RNN network of 6 neurons without the power of tf cells\n",
    "n_inputs = 3\n",
    "n_neurons = 6\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "Wx = tf.Variable(tf.random_normal(shape=[n_inputs, n_neurons], dtype=tf.float32))\n",
    "Wy = tf.Variable(tf.random_normal(shape=[n_neurons, n_neurons], dtype=tf.float32))\n",
    "b = tf.Variable(tf.zeros([1, n_neurons], dtype=tf.float32))\n",
    "\n",
    "Y0 = tf.tanh(tf.matmul(X0, Wx) + b)\n",
    "Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b)\n",
    "\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                  instance0, instance1, instance2, instance3\n",
    "X0_batch = np.array([[0,1,2],   [3,4,5],   [6,7,8],  [9,0,1]]) # t=0\n",
    "X1_batch = np.array([[9,8,7],   [0,0,0],   [6,5,4],  [3,2,1]]) # t=1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.76432037 -0.91695583  0.97727591 -0.32062194 -0.67042279  0.14208993]\n",
      " [ 0.07333915 -0.99902272  1.         -0.99996823 -0.99998587 -0.99986333]\n",
      " [-0.6960423  -0.99998891  1.         -1.         -1.         -1.        ]\n",
      " [-0.66256243  0.99172556  1.         -0.99999994 -0.99999642 -1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(Y0_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.9996497  -0.99996477  1.         -1.         -1.         -1.        ]\n",
      " [-0.41848999  0.67247814 -0.23164959  0.9981429  -0.63004768  0.97460502]\n",
      " [-0.99871987 -0.5623796   1.         -0.9999975  -1.         -0.99999976]\n",
      " [-0.64565659 -0.90720129  0.99999148 -0.46441022 -0.99998224 -0.9999308 ]]\n"
     ]
    }
   ],
   "source": [
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Now the same RNN network with the use of tf cells\n",
    "\n",
    "X_0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X_1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, [X_0, X_1], dtype=tf.float32)\n",
    "Y_0, Y_1 = output_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.50482887  0.80509692  0.45999557  0.03189753  0.93911433 -0.79291445]\n",
      " [-0.99517113  0.99324089  0.79699486 -0.50808209  0.99994242 -0.99991232]\n",
      " [-0.99996436  0.99978703  0.93329275 -0.81847847  0.99999982 -0.99999982]\n",
      " [-0.99997419 -0.93404073 -0.98145795 -0.74395895  0.42677706 -0.99974197]]\n",
      "[[ -9.99999642e-01   9.99612868e-01   8.24952900e-01  -9.39361215e-01\n",
      "    9.99999940e-01  -1.00000000e+00]\n",
      " [ -9.20558631e-01   5.66656768e-01  -4.47062820e-01  -3.34600717e-01\n",
      "    5.60612857e-01  -2.99190283e-01]\n",
      " [ -9.99991357e-01   9.96022046e-01   3.16824056e-02  -9.36235011e-01\n",
      "    9.99991059e-01  -9.99999166e-01]\n",
      " [ -9.86770630e-01   7.47967899e-01   2.34305830e-04  -7.64231741e-01\n",
      "    9.79189038e-01  -9.56827343e-01]]\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "#                  instance0, instance1, instance2, instance3\n",
    "X_0_batch = np.array([[0,1,2],   [3,4,5],   [6,7,8],  [9,0,1]]) # t=0\n",
    "X_1_batch = np.array([[9,8,7],   [0,0,0],   [6,5,4],  [3,2,1]]) # t=1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y_0_val, Y_1_val = sess.run([Y_0, Y_1], feed_dict={X_0: X_0_batch, X_1: X_1_batch})\n",
    "\n",
    "print(Y_0_val)\n",
    "print(Y_1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Now the same RNN networks with tf cells and just a tensor with our n_steps\n",
    "n_inputs = 3\n",
    "n_neurons = 6\n",
    "n_steps = 2\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "X_seqs = tf.unstack(tf.transpose(X, perm=[1, 0, 2])) # we transforme X in a list of n_steps tensors of shape[None, n_inputs]\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, X_seqs, dtype=tf.float32)\n",
    "\n",
    "outputs = tf.transpose(tf.stack(output_seqs), perm=[1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = np.array([\n",
    "    # t = 0    t = 1\n",
    "    [[0,1,2], [9,8,7]], # instance 0\n",
    "    [[3,4,5], [0,0,0]], # instance 1\n",
    "    [[6,7,8], [6,5,4]], # instance 2\n",
    "    [[9,0,1], [3,2,1]], # instance 3\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.74332833 -0.29883853  0.00570595 -0.49935222 -0.28266123 -0.31899813]\n",
      "  [ 0.95952499 -0.08961026  0.99999583  0.95828569  0.99915183 -0.99999833]]\n",
      "\n",
      " [[ 0.95158476 -0.37783515  0.9595896  -0.01568618  0.71562892 -0.98797143]\n",
      "  [-0.33797461 -0.83774149  0.14631489  0.31666163  0.40735844 -0.87474936]]\n",
      "\n",
      " [[ 0.9916746  -0.45168886  0.99913996  0.47543386  0.96973479 -0.99985832]\n",
      "  [ 0.3373484  -0.90567183  0.99912858  0.97427893  0.99627727 -0.99996912]]\n",
      "\n",
      " [[-0.99209398 -0.73277915  0.99997538  0.62479281  0.9999373  -0.99960953]\n",
      "  [-0.09267516 -0.67475277  0.88905203  0.94988328  0.67071736 -0.98185629]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Now we use Dynamic Unrolling that permit us to run over the cell the appropriate number of times\n",
    "##### we can also set swap_memory=True if we want to swap the GPU's memory to the CPU's memory during \n",
    "##### backpropagation to avoid Out of memory errors.\n",
    "n_inputs = 3\n",
    "n_neurons = 6\n",
    "n_steps = 2\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.53025371  0.58454984 -0.60889852 -0.75752777  0.90663368  0.40981999]\n",
      "  [-0.99605227 -0.9983173  -0.51188105 -0.87043715  1.          0.99765992]]\n",
      "\n",
      " [[-0.98093081 -0.33391705 -0.8171016  -0.92095989  0.99998981  0.93225205]\n",
      "  [ 0.90081394  0.18810864 -0.28867733 -0.38355374 -0.04714653 -0.00770936]]\n",
      "\n",
      " [[-0.99939644 -0.87727314 -0.91998017 -0.9757545   1.          0.99414402]\n",
      "  [-0.92071438 -0.98946625 -0.57992405 -0.51652431  0.99999958  0.95227605]]\n",
      "\n",
      " [[-0.99730086 -0.99990761  0.99691075  0.8216545   0.99995518  0.95956993]\n",
      "  [-0.86190498 -0.98064798  0.84106147  0.70973712  0.96618319  0.53029609]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Now we starting to add complexity. What happend when the input sequence have variable lenghts\n",
    "##### such in words and sentences? We have to add the lenght of our sequence inputs \n",
    "\n",
    "seq_length = tf.placeholder(tf.float32, [None]) # the lenght of our input value\n",
    "\n",
    "##### Suppose one of our input sequences contains only one input instead of two, like in instance 1\n",
    "\n",
    "X_batch = np.array([\n",
    "    # t = 0    t = 1\n",
    "    [[0,1,2], [9,8,7]], # instance 0\n",
    "    [[3,4,5]], # instance 1\n",
    "    [[6,7,8], [6,5,4]], # instance 2\n",
    "    [[9,0,1], [3,2,1]], # instance 3\n",
    "])\n",
    "\n",
    "##### then we have to add a padding of zeros\n",
    "\n",
    "X_batch = np.array([\n",
    "    # t = 0    t = 1\n",
    "    [[0,1,2], [9,8,7]], # instance 0\n",
    "    [[3,4,5], [0,0,0]], # instance 1\n",
    "    [[6,7,8], [6,5,4]], # instance 2\n",
    "    [[9,0,1], [3,2,1]], # instance 3\n",
    "])\n",
    "seq_length_batch = np.array([2,1,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ...and then our dynamic RNN become\n",
    "n_inputs = 3\n",
    "n_neurons = 6\n",
    "n_steps = 2\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32, sequence_length=seq_length) # we add the lenght values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val, states_val = sess.run(\n",
    "        [outputs, states], feed_dict={X: X_batch, seq_length: seq_length_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.87804133  0.30256867  0.83663434 -0.08793465 -0.63203824  0.61946684]\n",
      "  [-0.9999423   0.72810918  0.99999636 -0.43976662 -0.99994302  0.99977416]]\n",
      "\n",
      " [[-0.99786919  0.27504775  0.99860525 -0.3433398  -0.99650282  0.98064446]\n",
      "  [ 0.          0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.99996501  0.24706851  0.99998915 -0.55638719 -0.99997288  0.99918735]\n",
      "  [-0.99812543  0.94318289  0.99978596 -0.37332469 -0.97179782  0.99302483]]\n",
      "\n",
      " [[ 0.67462504  0.22138624 -0.44368061 -0.95958883 -0.99317026  0.98140597]\n",
      "  [-0.72439784  0.43750948  0.98660934 -0.68022025 -0.64432818  0.2375631 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.9999423   0.72810918  0.99999636 -0.43976662 -0.99994302  0.99977416]\n",
      " [-0.99786919  0.27504775  0.99860525 -0.3433398  -0.99650282  0.98064446]\n",
      " [-0.99812543  0.94318289  0.99978596 -0.37332469 -0.97179782  0.99302483]\n",
      " [-0.72439784  0.43750948  0.98660934 -0.68022025 -0.64432818  0.2375631 ]]\n"
     ]
    }
   ],
   "source": [
    "print(states_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
