{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Chatbot with a seq2seq Model</h1> \n",
    "\n",
    "<h3>Introduction</h3>\n",
    "<p>Using a \"sequence to sequence\" model is one of the most stimulating ways to develop a chatbot, but also one of the most complex from a computational point of view. The algorithm must be trained with a large corpus of dialogues: as input receives a message and provides another one as output.</p>\n",
    "<p>I found the algorithm used in the fourth week of the HSE course on NLP (https://github.com/hse-aml/natural-language-processing/tree/master/week4) very clean and clear and I will use that as a basic model, at least in the way of structuring the task. There are several useful datasets for our purpose, as suggested by the HSE, I will start relyng on the Cornell Movie Dialogues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Data exploration and preparation</h4> \n",
    "<p>First of all I need to prepare our corpus of data, It is useful to take the functions already used for this purpose by <a href=\"https://github.com/Conchylicultor/DeepQA\" target=\"_blank\">DeepQ&A. I import files 'cornelldata.py' and 'textdata.py'</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83097/83097 [00:05<00:00, 15465.27it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'data/cornell/' \n",
    "max_sentence_len = 50  # I use just short sentences for the beginning  \n",
    "\n",
    "data = readCornellData(dataset_path, max_len = max_sentence_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Now, we just explore the data.</h4> \n",
    "<p>It is necessary to always keep in mind the dimension of the dataset, and how it is structured. But it is also necessary to be clear about its content: in this case each line is represented by a question / answer pair. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of our dataset:  101349 \n",
      "\n",
      "Three lines of our dataset:  [('gosh if only we could find kat a boyfriend', 'let me see what i can do'), ('cesc ma tete this is my head', 'right see youre ready for the quiz'), ('thats because its such a nice one', 'forget french')] \n",
      "\n",
      "The same lines in a more readable form: \n",
      " Q: gosh if only we could find kat a boyfriend \n",
      " A: let me see what i can do\n",
      " Q: cesc ma tete this is my head \n",
      " A: right see youre ready for the quiz\n",
      " Q: thats because its such a nice one \n",
      " A: forget french\n",
      " Q: there \n",
      " A: where\n",
      " Q: you have my word as a gentleman \n",
      " A: youre sweet\n",
      " Q: hi \n",
      " A: looks like things worked out tonight huh\n",
      " Q: you know chastity \n",
      " A: i believe we share an art instructor\n",
      " Q: have fun tonight \n",
      " A: tons\n"
     ]
    }
   ],
   "source": [
    "initial_data_len = len(data)\n",
    "print('Size of our dataset: ', initial_data_len, '\\n')\n",
    "print('Three lines of our dataset: ', data[:3], '\\n')\n",
    "\n",
    "print('The same lines in a more readable form: ')\n",
    "for line in data[:8]:\n",
    "    que, ans = line\n",
    "    print(' Q:', que, '\\n', 'A:', ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Data preparations</h4>\n",
    "<p>I prepares the sentences for our training. For this purpose I use some of the potential provided by the python NLTK module (<a href=\"https://www.nltk.org/\" target=\"_blank\">Natural Language Toolkit</a>), in particular to identify the stopwords. I then create a function that receives a sentence and applies a filter that simplifies it for our purposes (it reduces the sentence in lowercase characters, eliminates strange symbols and eliminates unnecessary spacing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/marcofosci/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def prepare_text(sentence):\n",
    "    '''A filter function to prepare our sentences.'''\n",
    "    \n",
    "    GOOD_SYMBOLS_RE = re.compile('[^a-z ]')\n",
    "    REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;#+_]')\n",
    "    REPLACE_SEVERAL_SPACES = re.compile('\\s+')\n",
    "\n",
    "    sentence = sentence.lower()\n",
    "    sentence = REPLACE_BY_SPACE_RE.sub(' ', sentence)\n",
    "    sentence = GOOD_SYMBOLS_RE.sub('', sentence)\n",
    "    sentence = REPLACE_SEVERAL_SPACES.sub(' ', sentence)\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<p>I create a function to apply the filter above to all the dataset:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    '''A utility function to prepare all dataset'''\n",
    "\n",
    "    new_data = []\n",
    "    for line in data:\n",
    "        new_line = []\n",
    "        for sentence in line:    \n",
    "            new_line.append(prepare_text(sentence))\n",
    "        new_data.append(new_line)\n",
    "        \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>A dictionary</h4>\n",
    "<p>At this point I create a dictionary of symbols that are allowed. It will be the dictionary that the neural network will use to interpret the inputs and generate the outputs. In our case the dictionary will use the letters of the alphabet (only lowercase characters) and three symbols ('^', '$', '#') that we will use respectively as initial symbol, final symbol, and padding respectively.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter2id = {symbol:i for i, symbol in enumerate('^$#abcdefghijklmnopqrstuvwxyz ')}\n",
    "id2letter = {i:symbol for symbol, i in letter2id.items()}\n",
    "\n",
    "start_symbol = '^'\n",
    "end_symbol = '$'\n",
    "padding_symbol = '#'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to get a clear view of our dictionary and conversion tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'^': 0, '$': 1, '#': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28, ' ': 29}  \n",
      " {0: '^', 1: '$', 2: '#', 3: 'a', 4: 'b', 5: 'c', 6: 'd', 7: 'e', 8: 'f', 9: 'g', 10: 'h', 11: 'i', 12: 'j', 13: 'k', 14: 'l', 15: 'm', 16: 'n', 17: 'o', 18: 'p', 19: 'q', 20: 'r', 21: 's', 22: 't', 23: 'u', 24: 'v', 25: 'w', 26: 'x', 27: 'y', 28: 'z', 29: ' '}\n"
     ]
    }
   ],
   "source": [
    "print(letter2id, ' \\n', id2letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Converting the Dataset to make it digestible to the Neural Network</h4>\n",
    "<p>I create a function that converts sentences into a padded sequence of symbol index. And then another function that on the contrary converts a sequence of indices into a sentence.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_ids(sentence, symbol2id, padded_len):\n",
    "    ''' \n",
    "    Converts a sequence of symbols to a padded sequence of their ids.\n",
    "    \n",
    "    Input:\n",
    "        sentence: (str), a sequence of our dictionary symbols\n",
    "        symbol2id: (dict), a mapping from original symbols to ids\n",
    "        padded_len: (int), the desirable length of the sequence.\n",
    "\n",
    "    Output: \n",
    "        sent_ids: (tuple) a list of ids \n",
    "        sent_len: (int) the original length of the sentence.\n",
    "    '''\n",
    "    \n",
    "    sent_ids = [] \n",
    "    sent_ids = [symbol2id[sentence[i]] for i in range(min(len(sentence),padded_len))]\n",
    "    \n",
    "    if len(sentence) == padded_len:\n",
    "        sent_ids[-1] = symbol2id['$']\n",
    "    else:\n",
    "        sent_ids += [symbol2id['$']]\n",
    "    \n",
    "    for i in range(padded_len-len(sentence)-1): \n",
    "        sent_ids += [symbol2id['#']]                     \n",
    "        \n",
    "    sent_len = sent_ids.index(1) + 1\n",
    "    \n",
    "    return sent_ids, sent_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_sentence(ids_sentence, id2symbol):\n",
    "    ''' Converts a sequence of idx in a sequence of symbols'''\n",
    "    return [id2symbol[i] for i in ids_sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Here is an example of their behaviour. <br/> I consider just the firs eight lines of our data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gosh if only we could find kat a boyfriend', 'cesc ma tete this is my head', 'thats because its such a nice one', 'there', 'you have my word as a gentleman', 'hi', 'you know chastity', 'have fun tonight'] \n",
      " ['let me see what i can do', 'right see youre ready for the quiz', 'forget french', 'where', 'youre sweet', 'looks like things worked out tonight huh', 'i believe we share an art instructor', 'tons']\n"
     ]
    }
   ],
   "source": [
    "Xa, Ya = [], []\n",
    "for line in data[:8]:\n",
    "    que, ans = line\n",
    "    Xa.append(que)\n",
    "    Ya.append(ans)\n",
    "    \n",
    "print(Xa, '\\n', Ya)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The input data of our neural network must have the same length. For this reason the conversion creates a list in which each line contains 'n' indices (in our case 20). </p>\n",
    "<p>To get an idea of what the indices represent we can convert our list with the function 'ids_to_sentence'. We observe that each sentence ends with the symbol '$'. When the sentence is less than 20 characters long, it is followed by many '#' symbols for the number of missing characters.</p>\n",
    "<p>The 'sentence_to_ids' function in addition to the list of indices also returns the actual length of each sentence.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 17, 21, 10, 29, 11, 8, 29, 17, 16, 14, 27, 29, 25, 7, 29, 5, 17, 23, 14, 1]\n",
      "[5, 7, 21, 5, 29, 15, 3, 29, 22, 7, 22, 7, 29, 22, 10, 11, 21, 29, 11, 21, 1]\n",
      "[22, 10, 3, 22, 21, 29, 4, 7, 5, 3, 23, 21, 7, 29, 11, 22, 21, 29, 21, 23, 1]\n",
      "[22, 10, 7, 20, 7, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "[27, 17, 23, 29, 10, 3, 24, 7, 29, 15, 27, 29, 25, 17, 20, 6, 29, 3, 21, 29, 1]\n",
      "[10, 11, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "[27, 17, 23, 29, 13, 16, 17, 25, 29, 5, 10, 3, 21, 22, 11, 22, 27, 1, 2, 2]\n",
      "[10, 3, 24, 7, 29, 8, 23, 16, 29, 22, 17, 16, 11, 9, 10, 22, 1, 2, 2, 2]\n",
      "\n",
      "gosh if only we coul$\n",
      "cesc ma tete this is$\n",
      "thats because its su$\n",
      "there$##############\n",
      "you have my word as $\n",
      "hi$#################\n",
      "you know chastity$##\n",
      "have fun tonight$###\n",
      "\n",
      "The lenght of each sentence: [21, 21, 21, 6, 21, 3, 18, 17]\n"
     ]
    }
   ],
   "source": [
    "se = []\n",
    "sl = []\n",
    "for x in Xa:\n",
    "    sentence, s_len = sentence_to_ids(x, letter2id, 20)\n",
    "    se.append(sentence)\n",
    "    print(sentence)\n",
    "    sl.append(s_len)\n",
    "    \n",
    "print('')\n",
    "for j in se:\n",
    "    print(''.join(ids_to_sentence(j, id2letter)))\n",
    "\n",
    "print('\\nThe lenght of each sentence:', sl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Batch generation</h4>\n",
    "<p>We do not pass the whole dataset into the neural network at one time. We will use mini-batches. We therefore create a function that allows us to create them starting from the initial dataset.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_to_ids(sentences, symbol2id, max_len):\n",
    "    '''\n",
    "    Prepares batches of indices: every sequences are padded to match the longest sequence in the batch,\n",
    "       if it's longer than max_len, then max_len is used instead.\n",
    "    \n",
    "    Input:\n",
    "        sentences: (list of str), the original sequences\n",
    "        symbol2id: (dict), a mapping from original symbols to ids\n",
    "        max_len: (int), max len of sequences allowed.\n",
    "    \n",
    "    Output\n",
    "        batch_ids: (list), lists of ids, \n",
    "        batch_ids_len: (list), actual lengths.\n",
    "    '''\n",
    "    \n",
    "    max_len_in_batch = min(max(len(s) for s in sentences) + 1, max_len)\n",
    "    \n",
    "    batch_ids, batch_ids_len = [], []\n",
    "    \n",
    "    for sent in sentences:\n",
    "        ids, ids_len = sentence_to_ids(sent, symbol2id, max_len_in_batch)\n",
    "        batch_ids.append(ids)\n",
    "        batch_ids_len.append(ids_len)\n",
    "    \n",
    "    return batch_ids, batch_ids_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We convert our dataset in batches of dimension batch_size:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(samples, batch_size):\n",
    "    '''\n",
    "    A generator of batches of size batch_size     \n",
    "    '''\n",
    "    X, Y = [], []\n",
    "    for i, (x, y) in enumerate(samples, 1):\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        if i % batch_size == 0:\n",
    "            yield X, Y\n",
    "            X, Y = [], []\n",
    "    if X and Y:\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>An example of the two previous functions, we generate 4 batches, the last one with only 2 elements<br/>\n",
    "I use just the xxx value (only the questions of our initial data pair) but we can do the same for our labels yyy.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gosh if only we could find kat a boyfriend', 'cesc ma tete this is my head', 'thats because its such a nice one', 'there', 'you have my word as a gentleman', 'hi']\n",
      "([[9, 17, 21, 10, 29, 11, 1], [5, 7, 21, 5, 29, 15, 1], [22, 10, 3, 22, 21, 29, 1], [22, 10, 7, 20, 7, 1], [27, 17, 23, 29, 10, 3, 1], [10, 11, 1, 2, 2, 2]], [7, 7, 7, 6, 7, 3])\n",
      "['you know chastity', 'have fun tonight', 'i was', 'well no', 'then thats all you had to say', 'but']\n",
      "([[27, 17, 23, 29, 13, 16, 1], [10, 3, 24, 7, 29, 8, 1], [11, 29, 25, 3, 21, 1], [25, 7, 14, 14, 29, 16, 1], [22, 10, 7, 16, 29, 22, 1], [4, 23, 22, 1, 2, 2]], [7, 7, 6, 7, 7, 4])\n",
      "['do you listen to this crap', 'i figured youd get to the good stuff eventually', 'what good stuff', 'the real you', 'no', 'wow']\n",
      "([[6, 17, 29, 27, 17, 23, 1], [11, 29, 8, 11, 9, 23, 1], [25, 10, 3, 22, 29, 9, 1], [22, 10, 7, 29, 20, 7, 1], [16, 17, 1, 2, 2, 2], [25, 17, 25, 1, 2, 2]], [7, 7, 7, 7, 3, 4])\n",
      "['she okay', 'they do to']\n",
      "([[21, 10, 7, 29, 17, 13, 1], [22, 10, 7, 27, 29, 6, 1]], [7, 7])\n"
     ]
    }
   ],
   "source": [
    "xxx, yyy = [],[]\n",
    "for xxx, yyy in generate_batches(data[:20], 6):\n",
    "    print(xxx)\n",
    "    xxx_ = batch_to_ids(xxx, letter2id, max_len = 6)\n",
    "    print(xxx_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The Neural Network</h3>\n",
    "<p>Encoder-Decoder is a great architecture, very useful in those operations where we have a series of input data and we need to generate a series of output data (sequence to sequence models). Simplifying, with these kind of Neural Network we divide the problem into two parts: in the first one, the encoding phase, we begin to collect the sequence of input data and we create an abstract representation; in the second one, the decoding phase, we start from the abstract representation we have created to generate the output data.</p> \n",
    "<p>Basically, I will use two Recurrent Neural Networks, where the first one encodes the input sequence into a real-valued vector and then the second one decodes this vector into the output sequence.</p>\n",
    "<p>To create the neural network I will use Tensorflow</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>I create the model as a class and I call it <b>Model</b>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The structure of our model includes: the initialization of our placeholders, the creation of embeddings, the encoding phase, the decoding phase, the calculation of the loss, the optimization, and then two separate modules for the predictions - one for the phase training and one to generate answers for new sentences.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(self, vocab_size, embeddings_size, hidden_size, \n",
    "               max_iter, start_symbol_id, end_symbol_id, padding_symbol_id):\n",
    "    \n",
    "    self.__declare_placeholders()\n",
    "    self.__create_embeddings(vocab_size, embeddings_size)\n",
    "    self.__build_encoder(hidden_size)\n",
    "    self.__build_decoder(hidden_size, vocab_size, max_iter, start_symbol_id, end_symbol_id)\n",
    "    \n",
    "    # Compute loss and back-propagate.\n",
    "    self.__compute_loss()\n",
    "    self.__perform_optimization()\n",
    "    \n",
    "    # Get predictions for evaluation.\n",
    "    self.train_predictions = self.train_outputs.sample_id\n",
    "    self.infer_predictions = self.infer_outputs.sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.__init__ = classmethod(init_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>I initialize the placeholders that will contain input batches and their length, output labels and their length, and then some parameters such as the learning rate and the dropout:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def declare_placeholders(self):\n",
    "    '''\n",
    "    Specifies placeholders for the model\n",
    "    '''\n",
    "    \n",
    "    # Placeholders for input and its actual lengths.\n",
    "    self.input_batch = tf.placeholder(shape=(None, None), dtype=tf.int32, name='input_batch')\n",
    "    self.input_batch_lengths = tf.placeholder(shape=(None, ), dtype=tf.int32, name='input_batch_lengths')\n",
    "   \n",
    "    # Placeholders for groundtruth and its actual lengths.\n",
    "    self.ground_truth = tf.placeholder(shape=(None, None), dtype=tf.int32, name='ground_truth') \n",
    "    self.ground_truth_lengths = tf.placeholder(shape=(None, ), dtype=tf.int32, name='ground_truth_lengths') \n",
    "\n",
    "    self.dropout_ph = tf.placeholder_with_default(tf.cast(1.0, tf.float32), shape=[])\n",
    "    self.learning_rate_ph = tf.placeholder(shape=[], dtype=tf.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.__declare_placeholders = classmethod(declare_placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>I start to built the layers of the Neural Network: I initialize the embeddings matrix using random values:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(self, vocab_size, embeddings_size):\n",
    "    '''\n",
    "    Specifies embeddings layer and embeds an input batch\n",
    "    '''\n",
    "\n",
    "    random_initializer = tf.random_uniform((vocab_size, embeddings_size), -1.0, 1.0)\n",
    "    self.embeddings = tf.Variable(random_initializer, name='embeddings', dtype = tf.float32)  \n",
    "    \n",
    "    # Perform embeddings lookup for self.input_batch. \n",
    "    self.input_batch_embedded = tf.nn.embedding_lookup(self.embeddings, self.input_batch)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.__create_embeddings = classmethod(create_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Encoding phase</h4>\n",
    "<p>I encode the input sequences to a real-valued vector. Input of the RNN is an embedded input batch. Since sentences in the same batch could have different actual lengths, I provide input lengths to avoid unnecessary computations. The final encoder state will be passed to a second RNN (decoder).</p>\n",
    "<p>I create the GRU cells - the neurons - and insert them into the Recurrent Neural Network. I use the dropout to reduce the risk of overfitting.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_encoder(self, hidden_size):\n",
    "    '''\n",
    "    Specifies encoder architecture and computes its output\n",
    "    '''\n",
    "\n",
    "    # Create GRUCell with dropout.\n",
    "    encoder_cell = tf.contrib.rnn.DropoutWrapper(\n",
    "        tf.contrib.rnn.GRUCell (num_units = hidden_size), \n",
    "        input_keep_prob = self.dropout_ph,\n",
    "        dtype = tf.float32\n",
    "        ) \n",
    "    \n",
    "    # Create RNN with the predefined cell.\n",
    "    _, self.final_encoder_state = tf.nn.dynamic_rnn(\n",
    "        cell = encoder_cell,\n",
    "        inputs = self.input_batch_embedded,\n",
    "        sequence_length = self.input_batch_lengths,\n",
    "        dtype = tf.float32\n",
    "        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.__build_encoder = classmethod(build_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Decoding phase</h4>\n",
    "<p>Now I have to generate the output sequences. To do this, I create a second RNN that will act as a decoder.</p>\n",
    "<p>During training the decoder uses also information about the true labels. However, during the prediction stage (which I called <i>inference</i>), the decoder can only use its own generated output from the previous step to feed it in at the next step. To differentiate the training phase from the inference one I create two distinct instances. TrainingHelper and GreedyEmbeddingHelper helps to differentiate the two phases.</p>\n",
    "\n",
    "<p>The decoding layer is also made up of GRU cells.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_decoder(self, hidden_size, vocab_size, max_iter, start_symbol_id, end_symbol_id):\n",
    "    '''\n",
    "    Specifies decoder architecture and computes the output.\n",
    "    \n",
    "        Uses different helpers:\n",
    "          - for train: feeding ground truth\n",
    "          - for inference: feeding generated output\n",
    "\n",
    "        As a result, self.train_outputs and self.infer_outputs are created. \n",
    "        Each of them contains two fields:\n",
    "          rnn_output (predicted logits)\n",
    "          sample_id (predictions).\n",
    "    '''\n",
    "\n",
    "    # Use start symbols as the decoder inputs at the first time step.\n",
    "    batch_size = tf.shape(self.input_batch)[0]\n",
    "    start_tokens = tf.fill([batch_size], start_symbol_id)\n",
    "    ground_truth_as_input = tf.concat([tf.expand_dims(start_tokens, 1), self.ground_truth], 1)\n",
    "    \n",
    "    # Use the embedding layer defined before to lookup embedings for ground_truth_as_input. \n",
    "    self.ground_truth_embedded = tf.nn.embedding_lookup(self.embeddings, ground_truth_as_input) \n",
    "     \n",
    "    # Create TrainingHelper for the train stage.\n",
    "    train_helper = tf.contrib.seq2seq.TrainingHelper(self.ground_truth_embedded, \n",
    "                                                     self.ground_truth_lengths)\n",
    "\n",
    "    # Create GreedyEmbeddingHelper for the inference stage.\n",
    "    # You should provide the embedding layer, start_tokens and index of the end symbol.\n",
    "    infer_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "        embedding = self.embeddings, \n",
    "        start_tokens = start_tokens, \n",
    "        end_token = end_symbol_id\n",
    "        ) \n",
    "    \n",
    "  \n",
    "    def decode(helper, scope, reuse=None):\n",
    "        '''\n",
    "        Creates decoder and return the results of the decoding with a given helper\n",
    "        '''\n",
    "        \n",
    "        with tf.variable_scope(scope, reuse=reuse):\n",
    "            # Create GRUCell with dropout. Do not forget to set the reuse flag properly.\n",
    "            decoder_cell = tf.contrib.rnn.DropoutWrapper(\n",
    "                tf.contrib.rnn.GRUCell (num_units = hidden_size, reuse = reuse), \n",
    "                input_keep_prob = self.dropout_ph,\n",
    "                dtype = tf.float32\n",
    "                ) \n",
    "            \n",
    "            # Create a projection wrapper.\n",
    "            decoder_cell = tf.contrib.rnn.OutputProjectionWrapper(decoder_cell, vocab_size, reuse = reuse)\n",
    "            \n",
    "            # Create BasicDecoder, pass the defined cell, a helper, and initial state.\n",
    "            # The initial state should be equal to the final state of the encoder!\n",
    "            decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                cell = decoder_cell,\n",
    "                helper = helper,\n",
    "                initial_state = self.final_encoder_state\n",
    "                ) \n",
    "\n",
    "            # The first returning argument of dynamic_decode contains two fields:\n",
    "            #   rnn_output (predicted logits)\n",
    "            #   sample_id (predictions)\n",
    "            outputs, dec_final_state = tf.contrib.seq2seq.dynamic_decode(\n",
    "                decoder = decoder, \n",
    "                output_time_major = False, \n",
    "                impute_finished = True,\n",
    "                maximum_iterations = max_iter\n",
    "                )\n",
    "\n",
    "            return outputs\n",
    "        \n",
    "    self.train_outputs = decode(train_helper, 'decode')\n",
    "    self.infer_outputs = decode(infer_helper, 'decode', reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.__build_decoder = classmethod(build_decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>And now the <b>loss function</b>:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(self):\n",
    "    '''\n",
    "    Computes sequence loss (masked cross-entopy loss with logits)\n",
    "    '''\n",
    "    \n",
    "    weights = tf.cast(tf.sequence_mask(self.ground_truth_lengths), dtype=tf.float32)\n",
    "\n",
    "    self.loss = tf.contrib.seq2seq.sequence_loss(\n",
    "        self.train_outputs.rnn_output, \n",
    "        self.ground_truth, \n",
    "        weights\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.__compute_loss = classmethod(compute_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the <b>optimization function</b> (I use the Adam optimizer passing the learning rate that I will establish from time to time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_optimization(self):\n",
    "    '''\n",
    "    Specifies train_op that optimizes self.loss\n",
    "    '''\n",
    "    \n",
    "    self.train_op = tf.contrib.layers.optimize_loss(\n",
    "        loss = self.loss,\n",
    "        global_step = tf.train.get_global_step(),\n",
    "        learning_rate = self.learning_rate_ph,\n",
    "        optimizer = 'Adam',\n",
    "        clip_gradients= 1.0,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.__perform_optimization = classmethod(perform_optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The function below transmits the batch data and parameters to the Neural Network:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_batch(self, session, X, X_seq_len, Y, Y_seq_len, learning_rate, dropout_keep_probability):\n",
    "    feed_dict = {\n",
    "            self.input_batch: X,\n",
    "            self.input_batch_lengths: X_seq_len,\n",
    "            self.ground_truth: Y,\n",
    "            self.ground_truth_lengths: Y_seq_len,\n",
    "            self.learning_rate_ph: learning_rate,\n",
    "            self.dropout_ph: dropout_keep_probability\n",
    "        }\n",
    "    pred, loss, _ = session.run([\n",
    "            self.train_predictions,\n",
    "            self.loss,\n",
    "            self.train_op], feed_dict=feed_dict)\n",
    "\n",
    "    return pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.train_on_batch = classmethod(train_on_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Finally the two <b>prediction functions</b>, with and without the loss function:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_batch(self, session, X, X_seq_len):\n",
    "    feed_dict = {\n",
    "            self.input_batch: X,\n",
    "            self.input_batch_lengths: X_seq_len\n",
    "        }\n",
    "    \n",
    "    pred = session.run([\n",
    "            self.infer_predictions\n",
    "            ], feed_dict=feed_dict)[0]\n",
    "    return pred\n",
    "\n",
    "def predict_for_batch_with_loss(self, session, X, X_seq_len, Y, Y_seq_len):\n",
    "\n",
    "    feed_dict = {\n",
    "            self.input_batch: X,\n",
    "            self.input_batch_lengths: X_seq_len,\n",
    "            self.ground_truth: Y,\n",
    "            self.ground_truth_lengths: Y_seq_len\n",
    "        }\n",
    "    \n",
    "    pred, loss = session.run([\n",
    "            self.infer_predictions,\n",
    "            self.loss,\n",
    "        ], feed_dict=feed_dict)\n",
    "    return pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.predict_for_batch = classmethod(predict_for_batch)\n",
    "Model.predict_for_batch_with_loss = classmethod(predict_for_batch_with_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Training phase</h4>\n",
    "<p>It is time to establish the parameters for the neural network. I used the sentences of our dataset with a maximum length of 50 characters. As the basic parameters for the moment, I will consider those already tested during the HSE course.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "model = Model(\n",
    "    vocab_size = len(letter2id),\n",
    "    embeddings_size = 20,\n",
    "    max_iter = 51,\n",
    "    hidden_size = 512,\n",
    "    start_symbol_id = letter2id['^'],\n",
    "    end_symbol_id = letter2id['$'],\n",
    "    padding_symbol_id = letter2id['#']\n",
    "    ) \n",
    "\n",
    "batch_size = 128 \n",
    "n_epochs = 10 \n",
    "learning_rate = 0.001 \n",
    "dropout_keep_probability = 0.5 \n",
    "max_len = 50 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Training set and Test set</h4>\n",
    "<p>Before starting the training phase, I divide my dataset into trainset and testset (to be able to test the results later). <br/>The ratio between the two will be 80% and 20%.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633\n"
     ]
    }
   ],
   "source": [
    "# Just to know the batch number for each era\n",
    "n_step = int(len(train_set) / batch_size)\n",
    "print(n_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>For convenience I generate a file of logs that I will use later to evaluate the performance of the algorithm (the trend and the time it takes for the training phase)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime('%Y_%m_%d_-%H_%M_%S')\n",
    "root_logdir = 'tf_logs'\n",
    "logdir = '{}/run-{}'.format(root_logdir, now)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "            \n",
    "invalid_number_prediction_counts = []\n",
    "all_model_predictions = []\n",
    "all_ground_truth = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>And now the training phase:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training... \n",
      "\n",
      "Train: epoch 1\n",
      "Epoch: [1/10], step: [1/633], loss: 3.406866\n",
      "Epoch: [1/10], step: [201/633], loss: 2.247396\n",
      "Epoch: [1/10], step: [401/633], loss: 1.910273\n",
      "Epoch: [1/10], step: [601/633], loss: 1.863026\n",
      "Test: epoch 1 loss: 1.63839\n",
      "X: woodward$##########################################\n",
      "Y: hmm$##############################################\n",
      "O: i dont know what are you doing to the stope$\n",
      "\n",
      "X: that too$##########################################\n",
      "Y: would the station put me up at a good hotel$######\n",
      "O: i dont know what are you doing to the stope$\n",
      "\n",
      "X: sure see you later$################################\n",
      "Y: bye$##############################################\n",
      "O: i dont know what are you doing to the stope$\n",
      "\n",
      "Train: epoch 2\n",
      "Epoch: [2/10], step: [1/633], loss: 1.824005\n",
      "Epoch: [2/10], step: [201/633], loss: 1.795414\n",
      "Epoch: [2/10], step: [401/633], loss: 1.719810\n",
      "Epoch: [2/10], step: [601/633], loss: 1.688869\n",
      "Test: epoch 2 loss: 1.56471\n",
      "X: five bucks$######################################\n",
      "Y: youre kidding right$#############################\n",
      "O: what do you mean i do$^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: what what is it$#################################\n",
      "Y: shes not here$###################################\n",
      "O: i dont know what i said you do it$^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: never mind the sir never mind the sir$###########\n",
      "Y: well sir i was just$#############################\n",
      "O: what do you mean i do$^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "Train: epoch 3\n",
      "Epoch: [3/10], step: [1/633], loss: 1.661953\n",
      "Epoch: [3/10], step: [201/633], loss: 1.581090\n",
      "Epoch: [3/10], step: [401/633], loss: 1.617631\n",
      "Epoch: [3/10], step: [601/633], loss: 1.577580\n",
      "Test: epoch 3 loss: 1.51123\n",
      "X: the man who hired me for this contract$###########\n",
      "Y: i dont get it$#####################################\n",
      "O: i dont know what i say$^^^^^\n",
      "\n",
      "X: do you remember where you lived$##################\n",
      "Y: it was warm i was outside the ocean$###############\n",
      "O: i dont know what i say$^^^^^\n",
      "\n",
      "X: ronny$############################################\n",
      "Y: is johnny here$####################################\n",
      "O: i dont know what i say$^^^^^\n",
      "\n",
      "Train: epoch 4\n",
      "Epoch: [4/10], step: [1/633], loss: 1.560051\n",
      "Epoch: [4/10], step: [201/633], loss: 1.581277\n",
      "Epoch: [4/10], step: [401/633], loss: 1.577785\n",
      "Epoch: [4/10], step: [601/633], loss: 1.547699\n",
      "Test: epoch 4 loss: 1.48491\n",
      "X: well you want to or not$#########################\n",
      "Y: ok its a date ill see you here then$###############\n",
      "O: i dont know what i say$^^^^^^^^^^^^\n",
      "\n",
      "X: oskar$###########################################\n",
      "Y: ludwig$############################################\n",
      "O: you dont know what i say$^^^^^^^^^^\n",
      "\n",
      "X: everything all right$############################\n",
      "Y: huhhuh you$########################################\n",
      "O: yes i dont know what i say$^^^^^^^^\n",
      "\n",
      "Train: epoch 5\n",
      "Epoch: [5/10], step: [1/633], loss: 1.478350\n",
      "Epoch: [5/10], step: [201/633], loss: 1.564766\n",
      "Epoch: [5/10], step: [401/633], loss: 1.566072\n",
      "Epoch: [5/10], step: [601/633], loss: 1.539598\n",
      "Test: epoch 5 loss: 1.3839\n",
      "X: im here$###########################################\n",
      "Y: you treat her nice$################################\n",
      "O: you dont know what i said i dont know what i said$^\n",
      "\n",
      "X: maybe you could back off just a little bit$########\n",
      "Y: what did you do$###################################\n",
      "O: i dont know what i said i dont know what i said$^^^\n",
      "\n",
      "X: you expect me to pimp madeleine$###################\n",
      "Y: i wasnt talking about madeleine$###################\n",
      "O: i dont know what i said i dont know what i said$^^^\n",
      "\n",
      "Train: epoch 6\n",
      "Epoch: [6/10], step: [1/633], loss: 1.506022\n",
      "Epoch: [6/10], step: [201/633], loss: 1.461349\n",
      "Epoch: [6/10], step: [401/633], loss: 1.448625\n",
      "Epoch: [6/10], step: [601/633], loss: 1.518916\n",
      "Test: epoch 6 loss: 1.36301\n",
      "X: yeah well this ones the cadillac of minivans$######\n",
      "Y: youre kidding me right$############################\n",
      "O: what do you mean$^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: sir its you thank ipthar$##########################\n",
      "Y: quellek what are you doing in there$###############\n",
      "O: i dont know what you do it$^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: i am going to lock him up$#########################\n",
      "Y: youre not supposed to punish my son mary$##########\n",
      "O: what do you mean$^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "Train: epoch 7\n",
      "Epoch: [7/10], step: [1/633], loss: 1.396473\n",
      "Epoch: [7/10], step: [201/633], loss: 1.402930\n",
      "Epoch: [7/10], step: [401/633], loss: 1.390948\n",
      "Epoch: [7/10], step: [601/633], loss: 1.484630\n",
      "Test: epoch 7 loss: 1.38945\n",
      "X: ive scheduled a medical for you$###################\n",
      "Y: its barely a scratch the dome broke my fall$#######\n",
      "O: you dont know what you want$^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: oh you were talking to jesse$######################\n",
      "Y: yes but just so i could find out who you were$#####\n",
      "O: i dont know what you want$^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: well ill be he does have a bicycle$################\n",
      "Y: who$###############################################\n",
      "O: what are you doing here$^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "Train: epoch 8\n",
      "Epoch: [8/10], step: [1/633], loss: 1.429464\n",
      "Epoch: [8/10], step: [201/633], loss: 1.469018\n",
      "Epoch: [8/10], step: [401/633], loss: 1.450663\n",
      "Epoch: [8/10], step: [601/633], loss: 1.476570\n",
      "Test: epoch 8 loss: 1.35028\n",
      "X: only at the very end$##############################\n",
      "Y: how do you feel after a shooting$##################\n",
      "O: i dont know what i think i want to talk to you$^^^^\n",
      "\n",
      "X: shes not here right now$###########################\n",
      "Y: but shes standing right next to you$###############\n",
      "O: what do you mean$^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: he dont tip you dont tip why$######################\n",
      "Y: he dont believe in it$#############################\n",
      "O: i dont know i know i know i know i know$^^^^^^^^^^^\n",
      "\n",
      "Train: epoch 9\n",
      "Epoch: [9/10], step: [1/633], loss: 1.403305\n",
      "Epoch: [9/10], step: [201/633], loss: 1.432021\n",
      "Epoch: [9/10], step: [401/633], loss: 1.442785\n",
      "Epoch: [9/10], step: [601/633], loss: 1.375370\n",
      "Test: epoch 9 loss: 1.33723\n",
      "X: one question$######################################\n",
      "Y: what$#############################################\n",
      "O: i dont know i dont know$^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: lando grab it$#####################################\n",
      "Y: lower it$#########################################\n",
      "O: i dont know i dont know$^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: detective williams detective williams$#############\n",
      "Y: detective williams here is that you jeffrey$######\n",
      "O: you dont know what i said$^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "Train: epoch 10\n",
      "Epoch: [10/10], step: [1/633], loss: 1.399776\n",
      "Epoch: [10/10], step: [201/633], loss: 1.433153\n",
      "Epoch: [10/10], step: [401/633], loss: 1.405481\n",
      "Epoch: [10/10], step: [601/633], loss: 1.382435\n",
      "Test: epoch 10 loss: 1.35312\n",
      "X: so youre really going to stay here$###############\n",
      "Y: that boy wants me to$##############################\n",
      "O: i dont know what you want to do$^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: she intends to change the future somehow$#########\n",
      "Y: i guess yeah oh shit$##############################\n",
      "O: i want to talk to you$^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "X: im going to put you on the third floor$###########\n",
      "Y: the third floor are low class rooms$###############\n",
      "O: i dont know what you want to do$^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "\n",
      "...training finished.\n"
     ]
    }
   ],
   "source": [
    "print('Start training... \\n')\n",
    "for epoch in range(n_epochs):  \n",
    "    random.shuffle(train_set)\n",
    "    random.shuffle(test_set)\n",
    "    \n",
    "    print('Train: epoch', epoch + 1)\n",
    "    for n_iter, (X_batch, Y_batch) in enumerate(generate_batches(train_set, batch_size=batch_size)):\n",
    "\n",
    "        # prepare the data (X_batch and Y_batch) for training\n",
    "        # using function batch_to_ids\n",
    "        X, X_seq_len = batch_to_ids(X_batch, letter2id, batch_size) \n",
    "        Y, Y_seq_len = batch_to_ids(Y_batch, letter2id, batch_size) \n",
    "        \n",
    "        predictions, loss = Model.train_on_batch(session, X, X_seq_len, Y, Y_seq_len, learning_rate, dropout_keep_probability) \n",
    "\n",
    "        if n_iter % 200 == 0:\n",
    "            file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())            \n",
    "            print(\"Epoch: [%d/%d], step: [%d/%d], loss: %f\" % (epoch + 1, n_epochs, n_iter + 1, n_step, loss))\n",
    "                \n",
    "    X_sent, Y_sent = next(generate_batches(test_set, batch_size=batch_size))\n",
    "\n",
    "    # prepare test data (X_sent and Y_sent) for predicting \n",
    "    # quality and computing value of the loss function\n",
    "    # using function batch_to_ids\n",
    "    X, X_seq_len = batch_to_ids(X_sent, letter2id, batch_size) \n",
    "    Y, Y_seq_len = batch_to_ids(Y_sent, letter2id, batch_size) \n",
    "    \n",
    "    predictions, loss = Model.predict_for_batch_with_loss(session, X, X_seq_len, Y, Y_seq_len) \n",
    "    print('Test: epoch', epoch + 1, 'loss:', loss,)\n",
    "    for x, y, p  in list(zip(X, Y, predictions))[:3]:\n",
    "        print('X:',''.join(ids_to_sentence(x, id2letter)))\n",
    "        print('Y:',''.join(ids_to_sentence(y, id2letter)))\n",
    "        print('O:',''.join(ids_to_sentence(p, id2letter)))\n",
    "        print('')\n",
    "\n",
    "    model_predictions = []\n",
    "    ground_truth = []\n",
    "    invalid_number_prediction_count = 0\n",
    "    # For the whole test set calculate ground-truth values (as integer numbers)\n",
    "    # and prediction values (also as integers) to calculate metrics.\n",
    "    # If generated by model number is not correct (e.g. '1-1'), \n",
    "    # increase invalid_number_prediction_count and don't append this and corresponding\n",
    "    # ground-truth value to the arrays.\n",
    "    for X_batch, Y_batch in generate_batches(test_set, batch_size=batch_size):\n",
    "\n",
    "        X, X_seq_len = batch_to_ids(X_batch, letter2id, batch_size) \n",
    "        test_ids_predictions = (Model.predict_for_batch(session, X, X_seq_len))\n",
    "        test_predictions = list(''.join(ids_to_sentence(i, id2letter)) for i in test_ids_predictions)\n",
    "        test_pred_end = list(k[:k.find('$')] for k in test_predictions)\n",
    "        \n",
    "        # convert test predictions and ground truth as integer and count errors\n",
    "        for z in zip(test_pred_end, Y_batch):\n",
    "            try:\n",
    "                model_predictions.append(int(z[0]))\n",
    "                ground_truth.append(int(z[1]))              \n",
    "            except:\n",
    "                invalid_number_prediction_count += 1\n",
    "\n",
    "    all_model_predictions.append(model_predictions)\n",
    "    all_ground_truth.append(ground_truth)\n",
    "    invalid_number_prediction_counts.append(invalid_number_prediction_count)\n",
    "            \n",
    "print('\\n...training finished.')\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Some tests</h4>\n",
    "<p>It is time to take random tests on our network's ability to respond effectively to new questions.</p>\n",
    "<p>for convenience I have created a function with which I can ask new questions to the neural network and see the answers it generates.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_question(self, session, xx, xx_len):\n",
    "    feed_dict = {\n",
    "            self.input_batch: xx,\n",
    "            self.input_batch_lengths: xx_len\n",
    "        }\n",
    "    \n",
    "    pred = session.run([\n",
    "            self.infer_predictions\n",
    "            ], feed_dict=feed_dict)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.predict_question = classmethod(predict_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\n",
      "[[11, 29, 14, 11, 13, 7, 29, 22, 17, 29, 9, 17, 29, 22, 17, 29, 21, 25, 11, 15, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]\n"
     ]
    }
   ],
   "source": [
    "question = ['i like to go to swim',]\n",
    "xx_len = [len(question[0]), ]\n",
    "print(xx_len)\n",
    "xx = [sentence_to_ids(question[0], letter2id, 50)[0], ]\n",
    "print(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: \n",
      "i like to go to swim \n",
      " what are you talking about$\n"
     ]
    }
   ],
   "source": [
    "predictions = Model.predict_question(session, xx, xx_len)\n",
    "print('Test: ')\n",
    "print(question[0], '\\n', ''.join(ids_to_sentence(predictions[0][0], id2letter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: \n",
      "are you a bot \n",
      " yes i do$ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = ['are you a bot',]\n",
    "xx_len = [len(question[0]), ]\n",
    "xx = [sentence_to_ids(question[0], letter2id, 50)[0], ]\n",
    "predictions = Model.predict_question(session, xx, xx_len)\n",
    "print('Test: ')\n",
    "print(question[0], '\\n', ''.join(ids_to_sentence(predictions[0][0], id2letter)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: \n",
      "what is your name \n",
      " its a place to be so sure i want to go to the polic \n",
      "\n",
      "please come with me \n",
      " i dont know what you want$^^^^^^^^^^^^^^^^^^^^^^^^^ \n",
      "\n",
      "hi \n",
      " her the way you want to go to me$^^^^^^^^^^^^^^^^^^ \n",
      "\n",
      "how are you \n",
      " im sorry i dont know what you want$^^^^^^^^^^^^^^^^ \n",
      "\n",
      "do you love me \n",
      " yes i do$^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ \n",
      "\n",
      "what s the meaning of life \n",
      " i dont know what you want to do$^^^^^^^^^^^^^^^^^^^ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "xx = []\n",
    "xx_len = []\n",
    "\n",
    "questions = ['what is your name', 'please come with me', 'hi', 'how are you', 'do you love me', 'what s the meaning of life']\n",
    "for q in questions:\n",
    "    xx_len += [len(q)]\n",
    "    xx += [sentence_to_ids(q, letter2id, 50)[0]]\n",
    "    \n",
    "predictions = Model.predict_question(session, xx, xx_len)\n",
    "print('Test: ')\n",
    "\n",
    "for i, q in enumerate (questions):\n",
    "    print(q, '\\n', ''.join(ids_to_sentence(predictions[0][i], id2letter)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: \n",
      "how is the weather today \n",
      " the way i want to go to the police$ \n",
      "\n",
      "let s have a dinner \n",
      " what are you talking about$^^^^^^^^ \n",
      "\n",
      "are you a bot \n",
      " yes i do$^^^^^^^^^^^^^^^^^^^^^^^^^^ \n",
      "\n",
      "why not \n",
      " because i want to talk to you$^^^^^ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "xx = []\n",
    "xx_len = []\n",
    "\n",
    "questions = ['how is the weather today', 'let s have a dinner', 'are you a bot', 'why not']\n",
    "for q in questions:\n",
    "    xx_len += [len(q)]\n",
    "    xx += [sentence_to_ids(q, letter2id, 50)[0]]\n",
    "    \n",
    "predictions = Model.predict_question(session, xx, xx_len)\n",
    "print('Test: ')\n",
    "\n",
    "for i, q in enumerate (questions):\n",
    "    print(q, '\\n', ''.join(ids_to_sentence(predictions[0][i], id2letter)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
